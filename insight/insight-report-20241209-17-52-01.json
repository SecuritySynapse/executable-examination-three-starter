{"amount_correct": 14, "percentage_score": 22, "report_time": "2024-12-09 22:52:01", "checks": [{"description": "Ensure that the README.md file exists inside of the root of the GitHub repository", "check": "ConfirmFileExists", "status": true, "path": "../README.md"}, {"description": "Delete the phrase 'Add Your Name Here' and add your own name as an Honor Code pledge in README.md", "check": "MatchFileFragment", "options": {"fragment": "Add Your Name Here", "count": 0, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 2 fragment(s) in the README.md or the output while expecting exactly 0"}, {"description": "Retype the every word in the Honor Code pledge in README.md", "check": "MatchFileFragment", "options": {"fragment": "I adhered to the Allegheny College Honor Code while completing this executable examination.", "count": 3, "exact": true}, "status": true, "path": "../README.md"}, {"description": "Indicate that you have completed all of the tasks in the README.md", "check": "MatchFileFragment", "options": {"fragment": "- [X]", "count": 11, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 0 fragment(s) in the README.md or the output while expecting exactly 11"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for README.md", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "../README.md", "diagnostic": "Found 8 fragment(s) in the README.md or the output while expecting exactly 0"}, {"description": "Ensure that question_one.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": true, "path": "questions/question_one.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_one.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": false, "path": "questions/question_one.py", "diagnostic": "Found 8 fragment(s) in the question_one.py or the output while expecting exactly 0"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_one.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 15, "exact": true}, "status": false, "path": "questions/question_one.py", "diagnostic": "Found 12 comment(s) in the question_one.py or the output"}, {"description": "Create a sufficient number of single-line comments in question_one.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": true, "path": "questions/question_one.py"}, {"description": "Ensure that test_question_one.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_one.py"}, {"description": "Ensure that question_two.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": true, "path": "questions/question_two.py"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_two.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": true, "path": "questions/question_two.py"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_two.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 11, "exact": true}, "status": false, "path": "questions/question_two.py", "diagnostic": "Found 5 comment(s) in the question_two.py or the output"}, {"description": "Create a sufficient number of single-line comments in question_two.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": true, "path": "questions/question_two.py"}, {"description": "Ensure that test_question_two.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_two.py"}, {"description": "Ensure that question_three.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": false, "path": "questions/question_three.py", "diagnostic": "Did not find the specified file in the questions directory"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_three.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": true, "path": "questions/question_three.py"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_three.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 6, "exact": true}, "status": false, "path": "questions/question_three.py", "diagnostic": "Found 0 comment(s) in a file or the output"}, {"description": "Create a sufficient number of single-line comments in question_three.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": false, "path": "questions/question_three.py", "diagnostic": "Found 0 comment(s) in a file or the output"}, {"description": "Ensure that test_question_three.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_three.py"}, {"description": "Ensure that question_four.py file exists in the questions/ directory", "check": "ConfirmFileExists", "status": false, "path": "questions/question_four.py", "diagnostic": "Did not find the specified file in the questions directory"}, {"description": "Complete all TODOs, remove the TODO markers, and rewrite comments for question_four.py", "check": "MatchFileFragment", "options": {"fragment": "TODO", "count": 0, "exact": true}, "status": true, "path": "questions/question_four.py"}, {"description": "Create a sufficient number of docstring (i.e., multiple-line) comments in question_four.py", "check": "CountMultipleLineComments", "options": {"language": "Python", "count": 15, "exact": true}, "status": false, "path": "questions/question_four.py", "diagnostic": "Found 0 comment(s) in a file or the output"}, {"description": "Create a sufficient number of single-line comments in question_four.py", "check": "CountSingleLineComments", "options": {"language": "Python", "count": 20, "exact": false}, "status": false, "path": "questions/question_four.py", "diagnostic": "Found 0 comment(s) in a file or the output"}, {"description": "Ensure that test_question_four.py file exists in the tests/ directory", "check": "ConfirmFileExists", "status": true, "path": "tests/test_question_four.py"}, {"description": "Run checks for Question 1 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_a\" --debug --no-fancy --report status --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement the Caesar cipher."}, {"SE": "R", "rationale": "Correctly implement the Caesar cipher."}]}, "CLO3": {"degree": [{"SE": "R", "rationale": "Perform secure network communication with a client using Caesar cipher."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_b\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement the Latin alphabet cipher."}, {"SE": "R", "rationale": "Correctly implement the Latin alphabet cipher."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f31ec973260>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_c\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement reverse string cryptography with a dictionary."}, {"SE": "R", "rationale": "Correctly implement reverse string cryptography with a dictionary."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f174085b020>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 1 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_one_part_d\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement and test a general-purpose function for cryptography."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_one_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fbe1727b170>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_a\" --debug --no-fancy --report status --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement the atbash cipher."}, {"SE": "R", "rationale": "Correctly implement the atbash cipher."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_b\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement a comprehensive transposition cipher."}, {"SE": "R", "rationale": "Correctly implement a comprehensive transposition cipher."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f53fcfbb9e0>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_c\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO2": {"degree": [{"CS": "R", "rationale": "Correctly implement encryption and decryption with ROT13."}, {"SE": "R", "rationale": "Correctly implement encryption and decryption with ROT13."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fdc0e43f320>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 2 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_two_part_d\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO3": {"degree": [{"CS": "R", "rationale": "Implement a general-purpose cryptography system that supports JSON-based network encoding."}, {"SE": "D", "rationale": "Implement a general-purpose cryptography system that supports JSON-based network encoding."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_two_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f031b161790>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_a\" --debug --no-fancy --report status --report debug", "objectives": {"CLO1": {"degree": [{"SE": "D", "rationale": "Correctly identify the threat of malware and implement a debugging statement mitigation."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_b\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO1": {"degree": [{"SE": "D", "rationale": "Correctly identify the threat of a weak cryptosystem and implement word crytanalysis."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_b\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f2116ceb200>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_c\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO1": {"degree": [{"SE": "D", "rationale": "Correctly identify the threat of a weak cryptosystem and implement non-word crytanalysis."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_c\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7f4b2c100920>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 3 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_three_part_d\" --no-fancy --report status --report setup --report debug", "objectives": {"CLO1": {"degree": [{"SE": "D", "rationale": "Correctly identify the threat of malware and implement a while loop mitigation."}]}}, "status": false, "diagnostic": "Parameter Information\n     \n     - project: .\n     - tests: tests\n     - report: [<ReportType.exitcode: 'status'>, <ReportType.setup: 'setup'>, <ReportType.debug: 'debug'>]\n     - mark: question_three_part_d\n     - maxfail: 10\n     - advice_method: AdviceMethod.api_key\n     - advice_model: None\n     - advice_server: None\n     - debug: False\n     - fancy: False\n     - syntax_theme: Theme.ansi_dark\n     - return_code: 0\n     - litellm_thread: <Thread(Thread-1 (load_litellm), initial)>\n     - display_report_type: ReportType.testadvice\n     - json_report_plugin: <pytest_jsonreport.plugin.JSONReport object at 0x7fb3fac5b2c0>\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 4 Part (a) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_four_part_a\" --debug --no-fancy --report status --report debug", "objectives": {"CLO3": {"degree": [{"CS": "R", "rationale": "Correctly identify multiple daemons that are insecurely running on the same port."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 4 Part (b) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_four_part_b\" --debug --no-fancy --report status --report debug", "objectives": {"CLO3": {"degree": [{"CS": "R", "rationale": "Correctly identify whether or not there are network daemons that have crashed."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 4 Part (c) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_four_part_c\" --debug --no-fancy --report status --report debug", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Correctly assign numerical scores for the effectiveness of authentication and authorization."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Run checks for Question 4 Part (d) with 'execexam' command and confirm correct exit code", "command": "poetry run execexam . tests/ --mark \"question_four_part_d\" --debug --no-fancy --report status --report debug", "objectives": {"CLO3": {"degree": [{"SE": "D", "rationale": "Correctly diagnose average level of network vulnerability with CVSS scores."}]}}, "status": false, "diagnostic": "Debugging Information\n     \n     \u2714 Validity check passed for command-line arguments.\n     \u2714 Started to capture standard output and error.\n     \u2714 Correctly ran pytest when using marks.\n     \u2714 Stopped capturing standard output and error.\n     \n     Overall Status\n     \n     \u2718 One or more checks failed."}, {"description": "Ensure that Question 1 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_one.py", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "questions/question_one.py:93:5: D103 Missing docstring in public function\n        |\n     93 | def encrypt_caesar_cipher(plaintext, shift):\n        |     ^^^^^^^^^^^^^^^^^^^^^ D103\n     94 |     result = \"\"\n     95 |     return result\n        |\n     \n     questions/question_one.py:98:5: D103 Missing docstring in public function\n         |\n      98 | def decrypt_caesar_cipher(ciphertext, shift):\n         |     ^^^^^^^^^^^^^^^^^^^^^ D103\n      99 |     result = \"\"\n     100 |     return result\n         |\n     \n     questions/question_one.py:103:5: D103 Missing docstring in public function\n         |\n     103 | def send_message_to_client_using_caesar_cipher(client, plaintext, shift):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     104 |     return None\n         |\n     \n     Found 3 errors."}, {"description": "Ensure that Question 1 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_one.py --check", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "Would reformat: questions/question_one.py\n     1 file would be reformatted"}, {"description": "Ensure that Question 1 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_one.py", "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "questions/question_one.py:82: error: Need type annotation for \"message_history\" (hint: \"message_history: list[<type>] = ...\")  [var-annotated]\n     questions/question_one.py:166: error: Need type annotation for \"encrypted\" (hint: \"encrypted: list[<type>] = ...\")  [var-annotated]\n     questions/question_one.py:172: error: Need type annotation for \"decrypted\" (hint: \"decrypted: list[<type>] = ...\")  [var-annotated]\n     questions/question_one.py:173: error: Incompatible return value type (got \"list[Any]\", expected \"str\")  [return-value]\n     Found 4 errors in 1 file (checked 1 source file)"}, {"description": "Ensure that Question 1 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_one.py --count", "fragment": 10, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 1 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_one.py --count", "fragment": 11, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 1 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_one.py --count", "fragment": 0, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_two.py", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "questions/question_two.py:8:1: I001 [*] Import block is un-sorted or un-formatted\n        |\n      6 |   # to the industry best practices for Python source code.\n      7 |   \n      8 | / from typing import Callable, List\n      9 | | import math\n     10 | | \n     11 | | # Introduction: Read This First! {{{\n        | |_^ I001\n     12 |   \n     13 |   # Keep in mind these considerations as you implement the required functions:\n        |\n        = help: Organize imports\n     \n     questions/question_two.py:112:5: D103 Missing docstring in public function\n         |\n     110 | # if the input message's length is not a multiple of the key.\n     111 | \n     112 | def encrypt_transposition_cipher(key, message):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     113 |     ciphertext = [\"\"] * key\n     114 |     return \"\".join(ciphertext)\n         |\n     \n     questions/question_two.py:117:5: D103 Missing docstring in public function\n         |\n     117 | def decrypt_transposition_cipher(key, message):\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     118 |     numOfColumns = int(math.ceil(len(message) / float(key)))\n     119 |     plaintext = [\"\"] * numOfColumns\n         |\n     \n     questions/question_two.py:168:5: D103 Missing docstring in public function\n         |\n     166 | # so that this function is correctly documented by an software engineer using it.\n     167 | \n     168 | def rot13_encrypt(plaintext):\n         |     ^^^^^^^^^^^^^ D103\n     169 |     result = \"\"\n     170 |     return result\n         |\n     \n     questions/question_two.py:173:5: D103 Missing docstring in public function\n         |\n     173 | def rot13_decrypt(ciphertext):\n         |     ^^^^^^^^^^^^^ D103\n     174 |     result = \"\"\n     175 |     return result\n         |\n     \n     questions/question_two.py:234:5: D103 Missing docstring in public function\n         |\n     232 | # so that this function is correctly documented by an software engineer using it.\n     233 | \n     234 | def apply_encryption_methods(\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     235 |     functions: List[Callable[[str], str]], plaintext: str\n     236 | ) -> str:\n         |\n     \n     questions/question_two.py:240:5: D103 Missing docstring in public function\n         |\n     240 | def apply_decryption_methods(\n         |     ^^^^^^^^^^^^^^^^^^^^^^^^ D103\n     241 |     functions: List[Callable[[str], str]], ciphertext: str\n     242 | ) -> str:\n         |\n     \n     Found 7 errors.\n     [*] 1 fixable with the `--fix` option."}, {"description": "Ensure that Question 2 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_two.py --check", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "Would reformat: questions/question_two.py\n     1 file would be reformatted"}, {"description": "Ensure that Question 2 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_two.py", "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": true}, {"description": "Ensure that Question 2 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_two.py --count", "fragment": 10, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_two.py --count", "fragment": 10, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 2 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_two.py --count", "fragment": 0, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_three.py", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "questions/question_three.py:1:1: E902 No such file or directory (os error 2)\n     Found 1 error."}, {"description": "Ensure that Question 3 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_three.py --check", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "error: Failed to format questions/question_three.py: No such file or directory (os error 2)"}, {"description": "Ensure that Question 3 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_three.py", "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "mypy: can't read file 'questions/question_three.py': No such file or directory"}, {"description": "Ensure that Question 3 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_three.py --count", "fragment": 5, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_three.py --count", "fragment": 5, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 3 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_three.py --count", "fragment": 0, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 4 follows industry-standard rules using the command 'ruff check'", "command": "poetry run ruff check questions/question_four.py", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "questions/question_four.py:1:1: E902 No such file or directory (os error 2)\n     Found 1 error."}, {"description": "Ensure that Question 4 adheres to an industry-standard format using the command 'ruff format'", "command": "poetry run ruff format questions/question_four.py --check", "objectives": {"CLO4": {"degree": [{"SE": "D", "rationale": "Evaluate the adherence to industry standards for implementation of secure algorithms."}]}}, "status": false, "diagnostic": "error: Failed to format questions/question_four.py: No such file or directory (os error 2)"}, {"description": "Ensure that Question 4 has correct type annotations using the command 'mypy'", "command": "poetry run mypy questions/question_four.py", "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "mypy: can't read file 'questions/question_four.py': No such file or directory"}, {"description": "Ensure that Question 4 has correct number of fully type annotated functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --fully-typed -f questions/question_four.py --count", "fragment": 5, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using correct type annotations."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 4 has correct number of documented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --documented -f questions/question_four.py --count", "fragment": 8, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}, {"description": "Ensure that Question 4 has no undocumented functions using the command 'symbex'", "check": "MatchCommandFragment", "options": {"command": "poetry run symbex -s --undocumented -f questions/question_four.py --count", "fragment": 0, "count": 1, "exact": true}, "objectives": {"CLO5": {"degree": [{"SE": "R", "rationale": "Implement a security solution using industry-standard documentation."}]}}, "status": false, "diagnostic": "Found 0 fragment(s) in the file or the output while expecting exactly 1"}]}